{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "TensorFlow version: 2.1.0\nEager execution is: True\nKeras version: 2.2.4-tf\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution is: {}\".format(tf.executing_eagerly()))\n",
    "print(\"Keras version: {}\".format(tf.keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the code being run on a gpu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "WARNING: Logging before flag parsing goes to stderr.\nW0702 16:48:58.858033  8060 deprecation.py:323] From <ipython-input-3-96aa08269762>:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.config.list_physical_devices('GPU')` instead.\nRunning on CPU\n"
    }
   ],
   "source": [
    "var = tf.Variable([3, 3])\n",
    "\n",
    "if tf.test.is_gpu_available():\n",
    "    print('Running on GPU')\n",
    "    print('GPU #0?')\n",
    "    print(var.device.endswith('GPU:0'))\n",
    "else:\n",
    "    print('Running on CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[]\n"
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaring variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t2 = tf.Variable([[1, 2, 3], [5, 4, 7], [3, 1, 3]], dtype = tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=89.0>\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=98.0>\n"
    }
   ],
   "source": [
    "# Assigning new values to a variable\n",
    "f1 = tf.Variable(89.)\n",
    "print(f1)\n",
    "\n",
    "f1.assign(98)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf.Tensor(42, shape=(), dtype=int64)\n"
    }
   ],
   "source": [
    "mol = tf.constant(42, dtype = tf.int64)\n",
    "print(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<tf.Variable 'Variable:0' shape=(3, 3) dtype=int32, numpy=\narray([[1, 2, 3],\n       [5, 4, 7],\n       [3, 1, 3]])>\ntf.Tensor([1 2 3 5 4 7 3 1 3], shape=(9,), dtype=int32)\n"
    }
   ],
   "source": [
    "print(t2)\n",
    "t3 = tf.reshape(t2, [9])\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf.Tensor(2, shape=(), dtype=int32)\ntf.Tensor(1, shape=(), dtype=int32)\n"
    }
   ],
   "source": [
    "print(tf.rank(t2))\n",
    "print(tf.rank(t3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1 5]\n"
    }
   ],
   "source": [
    "print(t2[0:2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "9\n"
    }
   ],
   "source": [
    "print(tf.size(input=t2).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf.Tensor(\n[[1. 1. 1.]\n [1. 1. 1.]\n [1. 1. 1.]], shape=(3, 3), dtype=float64)\n"
    }
   ],
   "source": [
    "print(t2/t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t2t = tf.transpose(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf.Tensor(\n[[14 34 14]\n [34 90 40]\n [14 40 19]], shape=(3, 3), dtype=int32)\n"
    }
   ],
   "source": [
    "print(tf.matmul(t2, t2t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=42.3>\ntf.Tensor(42, shape=(), dtype=int32)\n"
    }
   ],
   "source": [
    "t1 = tf.Variable(42.3, dtype = tf.float32)\n",
    "i = tf.cast(t1, dtype = tf.int32)\n",
    "print(t1)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ragged tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<tf.RaggedTensor [[5, 2, 6, 1], [], [4, 3, 2, 1, 5, 6, 7, 8], [3, 5, 2]]>\ntf.Tensor([5 2 6 1], shape=(4,), dtype=int32)\ntf.Tensor([], shape=(0,), dtype=int32)\ntf.Tensor([4 3 2 1 5 6 7 8], shape=(8,), dtype=int32)\n"
    }
   ],
   "source": [
    "ragged = tf.ragged.constant([[5, 2, 6, 1], [], [4, 3, 2, 1, 5, 6 ,7, 8], [3, 5, 2]])\n",
    "print(ragged)\n",
    "print(ragged[0])\n",
    "print(ragged[1])\n",
    "print(ragged[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<tf.RaggedTensor [[5, 2, 6, 1], [], [4, 10, 7], [8], [6, 7]]>\n"
    }
   ],
   "source": [
    "x = tf.RaggedTensor.from_row_splits(values=[5, 2, 6, 1, 4, 10, 7, 8, 6, 7], row_splits = [0, 4, 4, 7, 8, 10])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf.Tensor([16  4  0  4 36], shape=(5,), dtype=int32)\n"
    }
   ],
   "source": [
    "x = [1, 3, 5, 7, 11]\n",
    "y = 5\n",
    "d = tf.math.squared_difference(x, y)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=int32, numpy=12>"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "tf.reduce_mean(d)\n",
    "#axis = 0 to reduce rows\n",
    "#axis = 1 to reduce columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(3, 2, 1), dtype=float32, numpy=\narray([[[ 0.6171746 ],\n        [ 1.4923018 ]],\n\n       [[-0.3935163 ],\n        [-0.15667547]],\n\n       [[-0.2846362 ],\n        [-0.10861127]]], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "tf.random.normal([3, 2, 1], mean = 0, stddev = 1, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\narray([[0.10573411],\n       [0.03444111],\n       [0.82348216]], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "tf.random.uniform(shape = [3, 1], minval = 0, maxval = 1, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras, a high-level API for TF 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x = tf.cast(train_x/255.0, tf.float32), tf.cast(test_x/255.0, tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y, test_y = tf.cast(train_y, tf.int64), tf.cast(test_y, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.models.Sequential([tf.keras.layers.Flatten(), tf.keras.layers.Dense(512, activation = tf.nn.relu), tf.keras.layers.Dropout(0.2), tf.keras.layers.Dense(10, activation = tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = tf.keras.optimizers.Adam()\n",
    "model1.compile(optimizer = optimiser, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 60000 samples\nEpoch 1/10\n60000/60000 [==============================] - 54s 902us/sample - loss: 0.2195 - accuracy: 0.9351\nEpoch 2/10\n60000/60000 [==============================] - 44s 739us/sample - loss: 0.0968 - accuracy: 0.9707\nEpoch 3/10\n60000/60000 [==============================] - 39s 655us/sample - loss: 0.0706 - accuracy: 0.9777\nEpoch 4/10\n60000/60000 [==============================] - 38s 637us/sample - loss: 0.0531 - accuracy: 0.9826\nEpoch 5/10\n60000/60000 [==============================] - 38s 638us/sample - loss: 0.0442 - accuracy: 0.9853\nEpoch 6/10\n60000/60000 [==============================] - 38s 632us/sample - loss: 0.0373 - accuracy: 0.9875\nEpoch 7/10\n60000/60000 [==============================] - 38s 637us/sample - loss: 0.0304 - accuracy: 0.9896\nEpoch 8/10\n60000/60000 [==============================] - 42s 697us/sample - loss: 0.0286 - accuracy: 0.9908\nEpoch 9/10\n60000/60000 [==============================] - 39s 644us/sample - loss: 0.0242 - accuracy: 0.9920\nEpoch 10/10\n60000/60000 [==============================] - 37s 620us/sample - loss: 0.0223 - accuracy: 0.9923\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1ed05386e08>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "model1.fit(train_x, train_y, batch_size = batch_size, epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10000/10000 [==============================] - 3s 333us/sample - loss: 0.0768 - accuracy: 0.9793\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.07677479264282629, 0.9793]"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "model1.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten (Flatten)            multiple                  0         \n_________________________________________________________________\ndense (Dense)                multiple                  401920    \n_________________________________________________________________\ndropout (Dropout)            multiple                  0         \n_________________________________________________________________\ndense_1 (Dense)              multiple                  5130      \n=================================================================\nTotal params: 407,050\nTrainable params: 407,050\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating models with the add method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.Sequential()\n",
    "model2.add(tf.keras.layers.Flatten())\n",
    "model2.add(tf.keras.layers.Dense(512, activation = 'relu'))\n",
    "model2.add(tf.keras.layers.Dropout(0.2))\n",
    "model2.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "model2.compile(optimizer = tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 60000 samples\nEpoch 1/10\n60000/60000 [==============================] - 85s 1ms/sample - loss: 0.2205 - accuracy: 0.9349\nEpoch 2/10\n60000/60000 [==============================] - 76s 1ms/sample - loss: 0.0954 - accuracy: 0.9710\nEpoch 3/10\n60000/60000 [==============================] - 57s 952us/sample - loss: 0.0691 - accuracy: 0.9779\nEpoch 4/10\n60000/60000 [==============================] - 60s 997us/sample - loss: 0.0543 - accuracy: 0.9821\nEpoch 5/10\n60000/60000 [==============================] - 40s 668us/sample - loss: 0.0436 - accuracy: 0.9859\nEpoch 6/10\n60000/60000 [==============================] - 37s 614us/sample - loss: 0.0352 - accuracy: 0.9883\nEpoch 7/10\n60000/60000 [==============================] - 37s 614us/sample - loss: 0.0316 - accuracy: 0.9894\nEpoch 8/10\n60000/60000 [==============================] - 38s 640us/sample - loss: 0.0269 - accuracy: 0.9913\nEpoch 9/10\n60000/60000 [==============================] - 39s 645us/sample - loss: 0.0247 - accuracy: 0.9916\nEpoch 10/10\n60000/60000 [==============================] - 40s 662us/sample - loss: 0.0215 - accuracy: 0.9926\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1ed03e7a2c8>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "model2.fit(train_x, train_y, batch_size = 32, epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10000/10000 [==============================] - 4s 355us/sample - loss: 0.0725 - accuracy: 0.9817\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.07250103500729056, 0.9817]"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "model2.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition using the functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28,28))\n",
    "x = tf.keras.layers.Flatten()(inputs)\n",
    "x = tf.keras.layers.Dense(512, activation = 'relu', name = 'd1')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "predictions = tf.keras.layers.Dense(10, activation = tf.nn.softmax, name = 'd2')(x)\n",
    "\n",
    "model3 = tf.keras.Model(inputs = inputs, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_5 (InputLayer)         [(None, 28, 28)]          0         \n_________________________________________________________________\nflatten_8 (Flatten)          (None, 784)               0         \n_________________________________________________________________\nd1 (Dense)                   (None, 512)               401920    \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 512)               0         \n_________________________________________________________________\nd2 (Dense)                   (None, 10)                5130      \n=================================================================\nTotal params: 407,050\nTrainable params: 407,050\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 60000 samples\nEpoch 1/10\n60000/60000 [==============================] - 57s 948us/sample - loss: 0.2203 - accuracy: 0.9350\nEpoch 2/10\n60000/60000 [==============================] - 38s 630us/sample - loss: 0.0975 - accuracy: 0.9704\nEpoch 3/10\n60000/60000 [==============================] - 22s 371us/sample - loss: 0.0685 - accuracy: 0.9784\nEpoch 4/10\n60000/60000 [==============================] - 23s 377us/sample - loss: 0.0522 - accuracy: 0.9834\nEpoch 5/10\n60000/60000 [==============================] - 23s 378us/sample - loss: 0.0438 - accuracy: 0.9858\nEpoch 6/10\n60000/60000 [==============================] - 22s 372us/sample - loss: 0.0352 - accuracy: 0.9892\nEpoch 7/10\n60000/60000 [==============================] - 22s 369us/sample - loss: 0.0312 - accuracy: 0.9898\nEpoch 8/10\n60000/60000 [==============================] - 22s 367us/sample - loss: 0.0284 - accuracy: 0.9901\nEpoch 9/10\n60000/60000 [==============================] - 23s 377us/sample - loss: 0.0257 - accuracy: 0.9913\nEpoch 10/10\n60000/60000 [==============================] - 22s 373us/sample - loss: 0.0206 - accuracy: 0.9930\n10000/10000 [==============================] - 2s 222us/sample - loss: 0.0785 - accuracy: 0.9793\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.07854417262229245, 0.9793]"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "optimiser = tf.keras.optimizers.Adam()\n",
    "model3.compile(optimizer = optimiser, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model3.fit(train_x, train_y, batch_size = 32, epochs = epochs)\n",
    "\n",
    "model3.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subclassing the Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__()\n",
    "        inputs = tf.keras.Input(shape=(28, 28))\n",
    "        self.x0 = tf.keras.layers.Flatten()\n",
    "        self.x1 = tf.keras.layers.Dense(512, activation = 'relu', name = 'd1')\n",
    "        self.x2 = tf.keras.layers.Dropout(0.2)\n",
    "        self.predictions = tf.keras.layers.Dense(10, activation = tf.nn.softmax, name = 'd2')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.x0(inputs)\n",
    "        x = self.x1(x)\n",
    "        x = self.x2(x)\n",
    "\n",
    "        return self.predictions(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1875\n"
    }
   ],
   "source": [
    "model4 = MyModel()\n",
    "steps_per_epoch = len(train_x.numpy())//batch_size\n",
    "print(steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 60000 samples\nEpoch 1/10\n60000/60000 [==============================] - 56s 936us/sample - loss: 0.2191 - accuracy: 0.9352\nEpoch 2/10\n60000/60000 [==============================] - 37s 622us/sample - loss: 0.0941 - accuracy: 0.9708\nEpoch 3/10\n60000/60000 [==============================] - 31s 516us/sample - loss: 0.0686 - accuracy: 0.9781\nEpoch 4/10\n60000/60000 [==============================] - 34s 559us/sample - loss: 0.0517 - accuracy: 0.9834\nEpoch 5/10\n60000/60000 [==============================] - 31s 518us/sample - loss: 0.0428 - accuracy: 0.9857\nEpoch 6/10\n60000/60000 [==============================] - 32s 531us/sample - loss: 0.0368 - accuracy: 0.9878\nEpoch 7/10\n60000/60000 [==============================] - 31s 523us/sample - loss: 0.0331 - accuracy: 0.9887\nEpoch 8/10\n60000/60000 [==============================] - 24s 398us/sample - loss: 0.0248 - accuracy: 0.9919\nEpoch 9/10\n60000/60000 [==============================] - 18s 298us/sample - loss: 0.0244 - accuracy: 0.9919\nEpoch 10/10\n60000/60000 [==============================] - 18s 292us/sample - loss: 0.0227 - accuracy: 0.9923\n10000/10000 [==============================] - 2s 183us/sample - loss: 0.0818 - accuracy: 0.9794\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.08180836250958273, 0.9794]"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "model4.compile(optimizer = tf.keras.optimizers.Adam(), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model4.fit(train_x, train_y, batch_size=batch_size, epochs = epochs)\n",
    "model4.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using data Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "buffer_size = 10000\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(batch_size).shuffle(buffer_size)\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x, y: (tf.image.random_flip_left_right(x), y))\n",
    "train_dataset = train_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-48bc0d4d46ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0moptimiser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).batch(batch_size).shuffle(buffer_size)\n",
    "test_dataset = test_dataset.repeat()\n",
    "\n",
    "steps_per_epoch = len(train_x)//batch_size\n",
    "optimiser = tf.keras.optimizers.Adam()\n",
    "model5.compile(optimizer = optimiser, loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model5.fit(train_dataset, batch_size=batch_size, epochs=epochs, steps_per_epochs = steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('./model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "new_model = load_model('./model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save the weights only\n",
    "new_model.save_weights('./model_weights.h5')\n",
    "\n",
    "new_model.load_weights('./model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%latex\n",
    "$sin(x)/x$\n",
    "\\bo{available datasets : }\n",
    "boston_housing, cifar10, cifar100, fashion_mnist, imdb, mnist, reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n32768/29515 [=================================] - 0s 1us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n26427392/26421880 [==============================] - 7s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n8192/5148 [===============================================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n4423680/4422102 [==============================] - 1s 0us/step\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((array([[[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         ...,\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n  array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)),\n (array([[[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         ...,\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n  array([9, 2, 1, ..., 8, 1, 5], dtype=uint8)))"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitbaseconda7b013a39607b49b2b95d3af1a103821a",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}